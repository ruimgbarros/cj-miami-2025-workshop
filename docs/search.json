[
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "AI Agents for Data Journalism",
    "section": "",
    "text": "If you have been following the buzz around AI, genAI and LLMs, you have likely heard about AI agents. For a while, I believed it was just another buzzword for prompt engineering. Some kind of “roleplay” or persona prompting where you would say to an LLM on how to behave and it would follow that role.\nAnd I guess there’s nothing wrong with that, but for a while my mind was elsewhere. I’ve been a data journalist for over ten years. And experience has taught me to keep an eye on new technologies while always asking myself: “How can this be useful for journalism?”\nWhen I first used an LLM for a story, I realized that, contrary to other Silicon Valley buzz words, AI agents were actually something different. Something that could really help journalists in their work.\nOr, in other words: I stopped asking myself on how to use this as a product to speed workflows or making things easier and started asking myself: “What kind of stories we can now do because we now have this technology?”.\nAnd that’s when agents clicked for me.",
    "crumbs": [
      "CJ Miami 2025 Workshop",
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#but-first-a-bit-of-history",
    "href": "introduction.html#but-first-a-bit-of-history",
    "title": "AI Agents for Data Journalism",
    "section": "But first, a bit of history",
    "text": "But first, a bit of history\n\n\n\nWorkshop context\n\n\nAt first, there was light. Then there was the computer. And pretty soon as those things started to be reachable to reporters, people started wondering how they could use it for new kinds of reporting.\nThat made journalists start to take interest in data. And in programming. And because no one really knew pretty well what they were doing, they started to experiment. To tinker. To hack. And to share online.\nThere was, although, a problem. Computers, they are great. But they used to be quite literal: you either gave them the precise, proper instructions, or they would fail catastrophically.\nThat also meant that you either had structured data, or you couldn’t do the simple tricks of data journalism.",
    "crumbs": [
      "CJ Miami 2025 Workshop",
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#why-does-ai-change-this",
    "href": "introduction.html#why-does-ai-change-this",
    "title": "AI Agents for Data Journalism",
    "section": "Why does AI change this?",
    "text": "Why does AI change this?\nIn my opinion, AI changes this because it brings a new level of flexibility to the table. Sure, you still need labels to count. PDFs aren’t going to parse themselves. But what used to require rigid, precise instructions, can now be done with a degree of “freedom”.\nIf software developement was solid, AI is a fluid gooey thing that can adapt to different situations. It can understand context, it can “read” and “interpret” unstructured data. And turn it into structured data.\n\n\n\nAI as fluid software",
    "crumbs": [
      "CJ Miami 2025 Workshop",
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#got-it-but-what-are-agents-and-why-should-i-care",
    "href": "introduction.html#got-it-but-what-are-agents-and-why-should-i-care",
    "title": "AI Agents for Data Journalism",
    "section": "Got it, but what are agents and why should I care?",
    "text": "Got it, but what are agents and why should I care?\nBecause if using an LLM is like asking something and get an answer back, using agents allows us to prepare more complex workflows.\nThink of simple prompting like asking a colleague a single question: “What’s in this budget document?” You get one answer, and that’s it.\nAgents is more like assembling a team that will work on a set of tasks.\nThey can: - Figure out what information they need; - Classify the information; - Write down information into a database; - Decide what to do next based on that information;\nThe difference? Simple prompting is a single request-response. Agents can plan, use tools, remember context, and iterate.\n\nKey Characteristics of Agents\nWhat makes something an “agent” rather than just a fancy prompt? Here are the key capabilities:\n\nPlanning: Can break down complex tasks into steps. Instead of trying to do everything at once, an agent might think “First I’ll extract the numbers, then compare them, then look for anomalies.”\nTool Use: Can search databases, call APIs, run calculations, access external information. Not limited to what’s in its training data or your prompt.\nMemory: Tracks what it’s learned and avoids repeating work. Remembers the context of the investigation across multiple interactions.\nIteration: Refines its approach based on what it discovers. If initial search turns up nothing, it tries a different angle.\nDecision-Making: Chooses next actions based on context. Knows when to dig deeper vs. when to move on.",
    "crumbs": [
      "CJ Miami 2025 Workshop",
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#warning",
    "href": "introduction.html#warning",
    "title": "AI Agents for Data Journalism",
    "section": "⚠️ Warning:",
    "text": "⚠️ Warning:\nI have my own beliefs about AI. Some of them is that there’s no journalistic usage when there’s no human in the loop.\nI also believe that it’s easy to entrench ourselves in either AI doomers or boosters camps.\nAs usual, I think it’s good to keep one foot on each side.\nHere are my main ethical guidelines for using AI in journalism:\n\nHuman Oversight Always: AI assists journalists, it doesn’t replace them. Every output needs human review.\nTransparency: Disclose when AI was used in your reporting process. Readers deserve to know. When possible, publish the prompts used.\nVerification: Always verify AI findings before publication. If you can’t verify it, don’t publish it.\nAttribution: Credit your sources, not the AI. The AI is how you found the information, not the source.\nPrivacy: Be careful what information you put in prompts. Sensitive data stays sensitive.",
    "crumbs": [
      "CJ Miami 2025 Workshop",
      "Introduction"
    ]
  },
  {
    "objectID": "introduction.html#prerequisites",
    "href": "introduction.html#prerequisites",
    "title": "AI Agents for Data Journalism",
    "section": "Prerequisites",
    "text": "Prerequisites\nI promised the workshop is open to everyone and I mean it. If you have ever used R, you will be able to follow along.\nI intend to replicate the examples in Python and JavaScript later, but for now R is the main language.\nIf you have never used R before, don’t worry. The concepts are explained in plain English. And we will be building the use cases together.\n\nBut I want to follow along!\nCool! Here are the things you need:\n\nR installed on your computer;\nAn IDE; I’m using Positron;\nAn OpenRouter API key. You can get one here OpenRouter. OpenRouter is a pretty cool service that allows you to use different open source LLMs through a single API. The free tier should be enough for the workshop.",
    "crumbs": [
      "CJ Miami 2025 Workshop",
      "Introduction"
    ]
  },
  {
    "objectID": "patterns/04-orchestrator-workers.html#what-is-this-pattern",
    "href": "patterns/04-orchestrator-workers.html#what-is-this-pattern",
    "title": "Pattern 4: Orchestrator-Workers",
    "section": "What Is This Pattern?",
    "text": "What Is This Pattern?\nOrchestrator-Workers is like an editor coordinating multiple specialized reporters. A central “orchestrator” agent delegates tasks to “worker” agents with specific expertise, monitors their progress, and integrates their findings into a coherent final product.\nThis pattern is ideal for complex investigations where different aspects require different expertise. The orchestrator plans the work, assigns tasks, and synthesizes results - much like an editor manages a team on a major investigation.\nIt’s like combining routing and parallelization with an added layer of coordination and synthesis.",
    "crumbs": [
      "CJ Miami 2025 Workshop",
      "Patterns",
      "4. Orchestrator-Workers"
    ]
  },
  {
    "objectID": "patterns/04-orchestrator-workers.html#how-it-works",
    "href": "patterns/04-orchestrator-workers.html#how-it-works",
    "title": "Pattern 4: Orchestrator-Workers",
    "section": "How It Works",
    "text": "How It Works\n\nConceptual Overview\nA central orchestrator agent breaks down complex tasks, delegates to specialized worker agents, coordinates their activities, and synthesizes results into a unified output.\n\n\nArchitecture Diagram\n\n\n\n\n\ngraph TB\n    In[Input]:::input --&gt; Orch1[Orchestrator&lt;br/&gt;Planning]:::llm\n\n    Orch1 --&gt; Worker1[Worker 1]:::llm\n    Orch1 --&gt; Worker2[Worker 2]:::llm\n    Orch1 --&gt; Worker3[Worker 3]:::llm\n\n    Worker1 --&gt; Orch2[Orchestrator&lt;br/&gt;Integration]:::llm\n    Worker2 --&gt; Orch2\n    Worker3 --&gt; Orch2\n\n    Orch2 --&gt; Out[Output]:::output\n\n    classDef input fill:#8B4444,stroke:#6B3333,color:#fff\n    classDef llm fill:#4A7C59,stroke:#3A6B49,color:#fff\n    classDef output fill:#8B4444,stroke:#6B3333,color:#fff\n\n\n Orchestrator-Workers: Coordinated Specialist Agents",
    "crumbs": [
      "CJ Miami 2025 Workshop",
      "Patterns",
      "4. Orchestrator-Workers"
    ]
  },
  {
    "objectID": "patterns/05-evaluator-optimizer.html#what-is-this-pattern",
    "href": "patterns/05-evaluator-optimizer.html#what-is-this-pattern",
    "title": "Pattern 5: Evaluator-Optimizer",
    "section": "What Is This Pattern?",
    "text": "What Is This Pattern?\nEvaluator-Optimizer is like having a writer and editor work together iteratively. One AI generates content, another evaluates it and provides feedback, and the first AI revises based on that feedback. This cycle continues until quality standards are met.\nThis pattern excels when you need high-quality output and can afford multiple iterations.",
    "crumbs": [
      "CJ Miami 2025 Workshop",
      "Patterns",
      "5. Evaluator-Optimizer"
    ]
  },
  {
    "objectID": "patterns/05-evaluator-optimizer.html#how-it-works",
    "href": "patterns/05-evaluator-optimizer.html#how-it-works",
    "title": "Pattern 5: Evaluator-Optimizer",
    "section": "How It Works",
    "text": "How It Works\n\nConceptual Overview\nA generator AI creates initial output, an evaluator AI critiques it and suggests improvements, the generator revises, and the cycle repeats until quality thresholds are met or maximum iterations reached.\n\n\nArchitecture Diagram\n\n\n\n\n\ngraph LR\n    In[Input]:::input --&gt; Gen1[Generator]:::llm\n    Gen1 --&gt;|Draft| Eval[Evaluator]:::llm\n    Eval --&gt;|Pass| Out[Output]:::output\n    Eval --&gt;|Fail + Feedback| Gen2[Generator&lt;br/&gt;Revision]:::llm\n    Gen2 --&gt;|Revised Draft| Eval\n\n    classDef input fill:#8B4444,stroke:#6B3333,color:#fff\n    classDef llm fill:#4A7C59,stroke:#3A6B49,color:#fff\n    classDef output fill:#8B4444,stroke:#6B3333,color:#fff\n\n\n Evaluator-Optimizer: Iterative Quality Improvement",
    "crumbs": [
      "CJ Miami 2025 Workshop",
      "Patterns",
      "5. Evaluator-Optimizer"
    ]
  },
  {
    "objectID": "patterns/02-routing.html#what-is-this-pattern",
    "href": "patterns/02-routing.html#what-is-this-pattern",
    "title": "Pattern 2: Routing",
    "section": "What Is This Pattern?",
    "text": "What Is This Pattern?\nRouting is like having a smart assignment editor that instantly categorizes incoming content and sends it to the right workflow. Instead of processing everything the same way, routing uses AI to classify content first, then directs it to specialized handling paths.",
    "crumbs": [
      "CJ Miami 2025 Workshop",
      "Patterns",
      "2. Routing"
    ]
  },
  {
    "objectID": "patterns/02-routing.html#how-it-works",
    "href": "patterns/02-routing.html#how-it-works",
    "title": "Pattern 2: Routing",
    "section": "How It Works",
    "text": "How It Works\n\nConceptual Overview\nInstead of manually sorting through incoming content, an initial AI call classifies the input and determines which processing path to follow.\n\n\nArchitecture Diagram\n\n\n\n\n\ngraph TD\n    In[Input]:::input --&gt; LLM1[LLM Call 1&lt;br/&gt;Classifier]:::llm\n    LLM1 --&gt;|Category A| LLM2[LLM Call 2]:::llm\n    LLM1 --&gt;|Category B| LLM3[LLM Call 3]:::llm\n    LLM1 --&gt;|Category C| Exit[Exit]:::output\n\n    LLM2 --&gt; Out1[Output]:::output\n    LLM3 --&gt; Out2[Output]:::output\n\n    classDef input fill:#8B4444,stroke:#6B3333,color:#fff\n    classDef llm fill:#4A7C59,stroke:#3A6B49,color:#fff\n    classDef output fill:#8B4444,stroke:#6B3333,color:#fff\n\n\n Routing: Classification and Workflow Direction",
    "crumbs": [
      "CJ Miami 2025 Workshop",
      "Patterns",
      "2. Routing"
    ]
  },
  {
    "objectID": "patterns/01-prompt-chaining.html#what-is-this-pattern",
    "href": "patterns/01-prompt-chaining.html#what-is-this-pattern",
    "title": "Pattern 1: Prompt Chaining",
    "section": "What Is This Pattern?",
    "text": "What Is This Pattern?\nPrompt chaining is like an assembly line for processing information. Instead of asking AI to do everything at once (which often leads to errors or incomplete analysis), you break the work into sequential steps where each step’s output becomes the next step’s input.\nThe magic is in the chaining: each AI call builds on the previous one’s work, gradually refining raw data into something we can work with.",
    "crumbs": [
      "CJ Miami 2025 Workshop",
      "Patterns",
      "1. Prompt Chaining"
    ]
  },
  {
    "objectID": "patterns/01-prompt-chaining.html#how-it-works",
    "href": "patterns/01-prompt-chaining.html#how-it-works",
    "title": "Pattern 1: Prompt Chaining",
    "section": "How It Works",
    "text": "How It Works\n\nConceptual Overview\nInstead of counting on one single call to the model, we can chain the output of one model into another.\n\n\nArchitecture Diagram\n\n\n\n\n\ngraph LR\n    In[Input]:::input --&gt; LLM1[LLM Call 1]:::llm\n    LLM1 --&gt;|Output 1| LLM2[LLM Call 2]:::llm\n    LLM2 --&gt;|Output 2| LLM3[LLM Call 3]:::llm\n    LLM3 --&gt;|Output 3| Out[Final Output]:::output\n\n    classDef input fill:#8B4444,stroke:#6B3333,color:#fff\n    classDef llm fill:#4A7C59,stroke:#3A6B49,color:#fff\n    classDef output fill:#8B4444,stroke:#6B3333,color:#fff\n\n\n Prompt Chaining: Sequential Processing Pipeline",
    "crumbs": [
      "CJ Miami 2025 Workshop",
      "Patterns",
      "1. Prompt Chaining"
    ]
  },
  {
    "objectID": "patterns/06-autonomous-agent.html#what-is-this-pattern",
    "href": "patterns/06-autonomous-agent.html#what-is-this-pattern",
    "title": "Pattern 6: Autonomous Agent",
    "section": "What Is This Pattern?",
    "text": "What Is This Pattern?\nAutonomous Agent is the most advanced pattern - a self-directed AI that can plan its own approach, use tools, and iterate toward a goal with minimal human guidance. Think of it like giving a reporter an assignment and letting them figure out the best investigative path.\nUnlike other patterns where you define the workflow, an autonomous agent decides its own next steps based on what it discovers. It can search databases, read documents, reason about findings, and determine when it has sufficient information.\nIt’s, in my opinion, the only one I don’t think we should be using :).",
    "crumbs": [
      "CJ Miami 2025 Workshop",
      "Patterns",
      "6. Autonomous Agent"
    ]
  },
  {
    "objectID": "patterns/06-autonomous-agent.html#how-it-works",
    "href": "patterns/06-autonomous-agent.html#how-it-works",
    "title": "Pattern 6: Autonomous Agent",
    "section": "How It Works",
    "text": "How It Works\n\nConceptual Overview\nAn autonomous agent receives a goal, creates its own plan, uses available tools to gather information, reflects on progress, and iteratively works toward completion - all with minimal human intervention.\n\n\nArchitecture Diagram\n\n\n\n\n\ngraph TB\n    In[Goal]:::input --&gt; Agent[Agent&lt;br/&gt;Planning]:::llm\n    Agent --&gt; Decision{Complete?}\n    Decision --&gt;|No| Tools[Tool Use]:::llm\n    Tools --&gt; Agent\n    Decision --&gt;|Yes| Out[Output]:::output\n\n    classDef input fill:#8B4444,stroke:#6B3333,color:#fff\n    classDef llm fill:#4A7C59,stroke:#3A6B49,color:#fff\n    classDef output fill:#8B4444,stroke:#6B3333,color:#fff\n\n\n Autonomous Agent: Self-Directed Goal Pursuit",
    "crumbs": [
      "CJ Miami 2025 Workshop",
      "Patterns",
      "6. Autonomous Agent"
    ]
  },
  {
    "objectID": "patterns/03-parallelization.html#what-is-this-pattern",
    "href": "patterns/03-parallelization.html#what-is-this-pattern",
    "title": "Pattern 3: Parallelization",
    "section": "What Is This Pattern?",
    "text": "What Is This Pattern?\nParallelization is like sending multiple reporters to research different aspects of a story simultaneously. Instead of running AI tasks one after another, you run them all at the same time, then combine the results.\nIt differs from routing because instead of directing input to different paths based on classification, it launches multiple independent AI calls in parallel to gather diverse insights or data points.",
    "crumbs": [
      "CJ Miami 2025 Workshop",
      "Patterns",
      "3. Parallelization"
    ]
  },
  {
    "objectID": "patterns/03-parallelization.html#how-it-works",
    "href": "patterns/03-parallelization.html#how-it-works",
    "title": "Pattern 3: Parallelization",
    "section": "How It Works",
    "text": "How It Works\n\nConceptual Overview\nLaunch multiple independent AI calls simultaneously across different sources, perspectives, or data sets, then synthesize the results into a unified output.\n\n\nArchitecture Diagram\n\n\n\n\n\ngraph TB\n    In[Input]:::input --&gt; Dispatcher[Dispatcher]:::llm\n\n    Dispatcher --&gt; LLM1[LLM Call 1]:::llm\n    Dispatcher --&gt; LLM2[LLM Call 2]:::llm\n    Dispatcher --&gt; LLM3[LLM Call 3]:::llm\n    Dispatcher --&gt; LLM4[LLM Call 4]:::llm\n\n    LLM1 --&gt; Synth[Synthesizer]:::llm\n    LLM2 --&gt; Synth\n    LLM3 --&gt; Synth\n    LLM4 --&gt; Synth\n\n    Synth --&gt; Out[Output]:::output\n\n    classDef input fill:#8B4444,stroke:#6B3333,color:#fff\n    classDef llm fill:#4A7C59,stroke:#3A6B49,color:#fff\n    classDef output fill:#8B4444,stroke:#6B3333,color:#fff\n\n\n Parallelization: Simultaneous Multi-Source Processing",
    "crumbs": [
      "CJ Miami 2025 Workshop",
      "Patterns",
      "3. Parallelization"
    ]
  }
]