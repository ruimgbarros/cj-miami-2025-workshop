---
title: "Introduction to AI Agents for Journalism"
subtitle: "Understanding When and How to Use AI Agents"
author: "Rui Barros"
format:
  html:
    code-fold: show
    code-tools: true
---

## What Are AI Agents?

::: {.callout-note icon=false}
## Definition
**AI agents are software applications that use Large Language Models (LLMs) to autonomously perform specific tasks**‚Äîfrom answering research questions to coordinating complex workflows across multiple data sources.
:::

### Agents vs. Simple Prompting

```{mermaid}
%%| fig-width: 10
graph TB
    subgraph "Simple Prompting"
        A[User Input] --> B[Single LLM Call]
        B --> C[Direct Response]
    end

    subgraph "AI Agent"
        D[User Input] --> E[Planning]
        E --> F{Decision}
        F -->|Option 1| G[Action 1]
        F -->|Option 2| H[Action 2]
        G --> I[Tool Use]
        H --> I
        I --> J{More Steps?}
        J -->|Yes| E
        J -->|No| K[Final Response]
    end
```

**Key Differences:**

| Simple Prompting | AI Agents |
|-----------------|-----------|
| Single interaction | Multi-step workflows |
| No external tools | Can use databases, APIs, search |
| No memory between calls | Maintains context and state |
| Linear processing | Branching logic and decisions |
| Limited error handling | Can retry and adapt |

## Why Agents for Journalism?

Journalism often requires:
- üîç **Multi-step research**: Verify claims across multiple sources
- üìä **Complex data processing**: Extract, transform, and validate information
- ‚ö° **Speed and scale**: Handle breaking news and large datasets
- üéØ **Consistency**: Apply same standards across all content
- üîó **Integration**: Connect multiple information sources

Traditional single-prompt LLMs struggle with these tasks. Agents can handle them systematically.

## Real Newsroom Scenarios

### Scenario 1: Verifying a Political Claim

**Traditional Approach (Manual)**:
1. Read the claim
2. Search government databases
3. Check academic sources
4. Review news archives
5. Cross-reference statistics
6. Write summary
‚Üí **Time: 2-3 hours**

**AI Agent Approach**:
```python
# Simplified conceptual example
agent = FactCheckingAgent()
result = agent.verify_claim(
    claim="Unemployment rate decreased by 15% last quarter",
    sources=["government_stats", "news_archives", "academic_papers"]
)
# Agent automatically:
# 1. Searches all sources in parallel
# 2. Extracts relevant statistics
# 3. Cross-references data
# 4. Identifies discrepancies
# 5. Generates summary with sources
# ‚Üí Time: 2-3 minutes
```

### Scenario 2: Document Analysis

**Challenge**: Analyze a 200-page government budget report.

**Traditional Approach**:
- Manual reading: 4-6 hours
- Risk of missing key details
- Inconsistent note-taking

**AI Agent Approach**:
```python
agent = DocumentAnalysisAgent()
findings = agent.analyze_document(
    document="budget_2025.pdf",
    tasks=[
        "extract_key_changes",
        "compare_previous_year",
        "identify_newsworthy_items",
        "verify_calculations"
    ]
)
# Agent provides structured output with citations
```

## The 10 Critical Questions

Before implementing an AI agent, ask yourself:

::: {.callout-warning}
## Decision Framework
1. **Does this task require multiple steps?** If no, use simple prompting.
2. **Do I need to access external data sources?** Agents can connect to databases and APIs.
3. **Is accuracy critical?** Implement verification loops and human oversight.
4. **Will this be repeated frequently?** Investment in agent development pays off.
5. **Can errors be caught and corrected?** Design for graceful error handling.
6. **Do I need an audit trail?** Agents can log every decision and action.
7. **Is real-time processing required?** Consider latency and costs.
8. **What are the ethical implications?** Always plan for transparency and oversight.
9. **How will humans stay in the loop?** Define intervention points.
10. **What happens if the agent fails?** Have fallback procedures.
:::

## When NOT to Use Agents

Agents are **not appropriate** for:

- ‚ùå Final editorial decisions
- ‚ùå Sensitive source communication
- ‚ùå Legal determinations
- ‚ùå Publishing without human verification
- ‚ùå Simple one-step tasks (use basic prompting instead)
- ‚ùå Situations requiring human empathy and judgment

## Hallucination Risks in Journalism

::: {.callout-important}
## Critical Awareness
LLMs can "hallucinate"‚Äîgenerate plausible but false information. In journalism, this is **unacceptable**.

**Mitigation Strategies**:
- **Chain of Verification**: Verify claims through multiple methods
- **Source Attribution**: Always cite sources
- **Human Review**: Final fact-checking by journalists
- **Confidence Scoring**: Flag uncertain information
- **Audit Trails**: Log all sources and reasoning
:::

### Example: Hallucination Detection

```python
# Conceptual example of verification pattern
def verify_with_chain_of_verification(claim):
    # Step 1: Initial verification
    verification_1 = check_against_primary_sources(claim)

    # Step 2: Cross-reference with alternative method
    verification_2 = check_against_academic_sources(claim)

    # Step 3: Compare results
    if verification_1 != verification_2:
        # Flag discrepancy for human review
        return {
            "status": "needs_review",
            "reason": "conflicting_sources",
            "details": [verification_1, verification_2]
        }

    return {
        "status": "verified",
        "confidence": calculate_confidence(verification_1, verification_2),
        "sources": merge_sources(verification_1, verification_2)
    }
```

## Six Patterns We'll Cover

In this workshop, you'll learn six proven agent architectures:

### 1. Augmented LLM
**Add tools and knowledge** to base LLM
- Database access
- Search capabilities
- Fact-checking APIs

### 2. Prompt Chaining
**Sequential processing** through multiple steps
- Extract ‚Üí Summarize ‚Üí Verify ‚Üí Report

### 3. Routing
**Intelligent classification** and task distribution
- Breaking news ‚Üí Priority workflow
- Feature story ‚Üí Research workflow

### 4. Parallelization (Sectioning)
**Simultaneous processing** across multiple sources
- Search 5 databases at once
- Aggregate results efficiently

### 5. Parallelization (Voting)
**Multiple verification methods** for consensus
- Same claim, different approaches
- Compare for consistency

### 6. Orchestrator-Workers
**Complex coordination** of specialized agents
- Main orchestrator delegates to specialists
- Synthesis of diverse findings

## Hands-On Philosophy

Each pattern includes:

::: {.panel-tabset}

### Concept
Plain-English explanation of how it works and when to use it.

### Architecture
Visual diagrams showing information flow.

### Use Case
Real journalism scenario where this pattern applies.

### Code Example
Working implementation you can run and modify.

### Ethical Considerations
Privacy, bias, and transparency implications.

:::

## Setup for Hands-On Examples

If you want to run the code examples (optional):

### Python Setup
```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install anthropic python-dotenv requests pandas
```

### API Key (Optional)
Create a `.env` file:
```bash
ANTHROPIC_API_KEY=your_api_key_here
```

::: {.callout-tip}
Don't have an API key? No problem! All examples include:
- Conceptual explanations
- Sample outputs
- Visual demonstrations

You can learn the patterns without running code.
:::

## Workshop Navigation

Use the navigation menu to explore:

1. **00-Introduction** (you are here)
2. **01-Augmented LLM**: Source verification
3. **02-Prompt Chaining**: Document analysis pipeline
4. **03-Routing**: Story classification
5. **04-Parallelization (Sectioning)**: Multi-source research
6. **05-Parallelization (Voting)**: Claim verification
7. **06-Orchestrator-Workers**: Complex investigations

---

::: {.callout-note}
## Questions?
Pause here for any questions before we dive into the first pattern.
:::

## Additional Resources

- [Anthropic: Building Effective Agents](https://www.anthropic.com/research/building-effective-agents)
- [OpenAI: Prompt Engineering Guide](https://platform.openai.com/docs/guides/prompt-engineering)
- [P√öBLICO Data Journalism Team](https://www.publico.pt/authors/equipa-de-dados-publico)

---

**Next**: [Pattern 1: Augmented LLM ‚Üí](01-augmented-llm.qmd)
